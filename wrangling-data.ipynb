{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Dados: Laboratório Educativo\n",
    "\n",
    "Bem-vindo ao laboratório de Análise de Dados! Neste projeto educativo quero explorar junto a vocês conceitos que formam a base da manipulação e análise de dados. Esse projeto é baseado no curso <a href='https://www.coursera.org/learn/data-analysis-with-python'>Data Analysis with Python</a> da plataforma Coursera. O tema aqui abordado diz respeito à segunda semana do curso, e é uma realização prática dos conceitos com um conjunto de dados colhido da plataforma Kaggle: <a href='https://www.kaggle.com/datasets/shariful07/student-mental-health'>Student Mental health</a>\n",
    "\n",
    "Ao final deste projeto, teremos adquirido habilidades essenciais para lidar com dados ausentes, ajustar tipos de dados conforme necessário, padronizar e normalizar atributos relevantes, visualizar dados por meio de gráficos de barras agrupadas usando binning e converter dados categóricos em variáveis indicadoras numéricas.\n",
    "\n",
    "Agradeço sinceramente à Coursera por proporcionar não apenas uma plataforma educativa abrangente e acessível, mas também por oferecer suporte financeiro (financial aid) que possibilita a prática de diversos curso. Expresso minha profunda gratidão à comunidade, cujo compartilhamento de conhecimento e apoio mútuo enriquece significativamente a experiência de aprendizado para todos.\n",
    "\n",
    "## 1. <a href=\"#1\">Lidar com Dados Ausentes</a>\n",
    "Uma análise de dados robusta requer a capacidade de lidar eficazmente com dados ausentes. Existem diversas abordagens para esse desafio, desde a exclusão de entradas incompletas até a imputação de valores faltantes. Vamos explorar essas técnicas, destacando suas aplicações e considerações práticas.\n",
    "\n",
    "## 2. <a href=\"#2\">Correção de Tipos de Dados</a>\n",
    "A consistência nos tipos de dados é fundamental. Neste laboratório, aprenderemos a identificar e corrigir tipos de dados inadequados, garantindo que cada variável seja interpretada corretamente. Isso é fundamental para evitar erros de análise e interpretação equivocada dos dados.\n",
    "\n",
    "## 3. <a href=\"#3\">Padronização e Normalização</a>\n",
    "Padronizar e normalizar dados são passos essenciais para comparar atributos em diferentes escalas. Vamos entender a diferença entre esses processos e quando aplicar cada um. Ao final, teremos dados prontos para análises mais precisas e significativas.\n",
    "\n",
    "## 4. <a href=\"#4\">Visualização com Gráficos de Barras Agrupadas (Binning)</a>\n",
    "A visualização é uma ferramenta poderosa na análise de dados. Abordaremos a técnica de binning, que agrupa dados em intervalos, permitindo uma representação mais clara e interpretável. Prepare-se para criar gráficos de barras agrupadas que revelarão padrões e tendências em seus conjuntos de dados.\n",
    "\n",
    "## 5. <a href=\"#5\">Conversão de Dados Categóricos</a>\n",
    "Nem sempre os algoritmos podem lidar diretamente com dados categóricos. Aprenderemos a converter essas variáveis em indicadores numéricos, tornando-as compatíveis com uma ampla gama de técnicas analíticas. Este passo é vital para garantir que todos os aspectos do seu conjunto de dados contribuam para análises robustas.\n",
    "\n",
    "Ao longo deste projeto, concentramo-nos não apenas em realizar tarefas, mas em compreender os motivos por trás de cada passo. Estamos prontos? Vamos começar a explorar e aprimorar nossas habilidades de análise de dados!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importanto as bibliotecas necessárias\n",
    "\n",
    "Vamos agora importar as bibliotecas necessárias para dar início ao nosso projeto. Embora a explicação detalhada sobre essa etapa não esteja incluída neste trabalho, é importante compreender que a importação de bibliotecas é uma prática comum na programação em Python. Para aprofundar esse conhecimento, recomendamos explorar recursos online, como a documentação oficial do Python (https://docs.python.org/3/) e tutoriais específicos disponíveis em plataformas de aprendizado, como a própria Coursera ou sites como W3Schools. Essa habilidade será valiosa ao longo do projeto e em futuras explorações na análise de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura do Arquivo CSV\n",
    "\n",
    "Vamos agora realizar a leitura do arquivo CSV que está armazenado localmente. O caminho que você está vendo na célula abaixo corresponde à localização do arquivo em **minha máquina**. Para prosseguir e ter acesso ao arquivo em sua máquina, siga os passos abaixo:\n",
    "\n",
    "1. **Baixe o arquivo:**\n",
    "   - Visite o link [Student Mental Health](https://www.kaggle.com/datasets/shariful07/student-mental-health) no Kaggle.\n",
    "   - Baixe o arquivo CSV disponível na página.\n",
    "2. **Salve o arquivo em sua máquina:**\n",
    "   - Após o download, salve o arquivo em uma localização acessível em sua máquina.\n",
    "3. **Atualize o caminho no código:**\n",
    "   - Caso você tenha salvado o arquivo em um diretório diferente, ajuste o caminho do arquivo no código para refletir a localização correta.\n",
    "\n",
    "Caso prefira, você também pode utilizar o arquivo que disponibilizei no mesmo diretório do projeto no GitHub. No entanto, baixar o arquivo do Kaggle é recomendado, pois fornece informações adicionais sobre os dados que podem ser úteis. Este procedimento é essencial para garantir que o código funcione corretamente e que você possa explorar o conjunto de dados de forma eficaz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Choose your gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>What is your course?</th>\n",
       "      <th>Your current year of Study</th>\n",
       "      <th>What is your CGPA?</th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Do you have Depression?</th>\n",
       "      <th>Do you have Anxiety?</th>\n",
       "      <th>Do you have Panic attack?</th>\n",
       "      <th>Did you seek any specialist for a treatment?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/7/2020 12:02</td>\n",
       "      <td>Female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>year 1</td>\n",
       "      <td>3.00 - 3.49</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/7/2020 12:04</td>\n",
       "      <td>Male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Islamic education</td>\n",
       "      <td>year 2</td>\n",
       "      <td>3.00 - 3.49</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/7/2020 12:05</td>\n",
       "      <td>Male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>BIT</td>\n",
       "      <td>Year 1</td>\n",
       "      <td>3.00 - 3.49</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/7/2020 12:06</td>\n",
       "      <td>Female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Laws</td>\n",
       "      <td>year 3</td>\n",
       "      <td>3.00 - 3.49</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/7/2020 12:13</td>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Mathemathics</td>\n",
       "      <td>year 4</td>\n",
       "      <td>3.00 - 3.49</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>13/07/2020 19:56:49</td>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>BCS</td>\n",
       "      <td>year 1</td>\n",
       "      <td>3.50 - 4.00</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>13/07/2020 21:21:42</td>\n",
       "      <td>Male</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Year 2</td>\n",
       "      <td>3.00 - 3.49</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>13/07/2020 21:22:56</td>\n",
       "      <td>Female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Nursing</td>\n",
       "      <td>Year 3</td>\n",
       "      <td>3.50 - 4.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>13/07/2020 21:23:57</td>\n",
       "      <td>Female</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Pendidikan Islam</td>\n",
       "      <td>year 4</td>\n",
       "      <td>3.50 - 4.00</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>18/07/2020 20:16:21</td>\n",
       "      <td>Male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Biomedical science</td>\n",
       "      <td>Year 2</td>\n",
       "      <td>3.00 - 3.49</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Timestamp Choose your gender   Age What is your course?  \\\n",
       "0         8/7/2020 12:02             Female  18.0          Engineering   \n",
       "1         8/7/2020 12:04               Male  21.0    Islamic education   \n",
       "2         8/7/2020 12:05               Male  19.0                  BIT   \n",
       "3         8/7/2020 12:06             Female  22.0                 Laws   \n",
       "4         8/7/2020 12:13               Male  23.0         Mathemathics   \n",
       "..                   ...                ...   ...                  ...   \n",
       "96   13/07/2020 19:56:49             Female  21.0                  BCS   \n",
       "97   13/07/2020 21:21:42               Male  18.0          Engineering   \n",
       "98   13/07/2020 21:22:56             Female  19.0             Nursing    \n",
       "99   13/07/2020 21:23:57             Female  23.0     Pendidikan Islam   \n",
       "100  18/07/2020 20:16:21               Male  20.0   Biomedical science   \n",
       "\n",
       "    Your current year of Study What is your CGPA? Marital status  \\\n",
       "0                       year 1        3.00 - 3.49             No   \n",
       "1                       year 2        3.00 - 3.49             No   \n",
       "2                       Year 1        3.00 - 3.49             No   \n",
       "3                       year 3        3.00 - 3.49            Yes   \n",
       "4                       year 4        3.00 - 3.49             No   \n",
       "..                         ...                ...            ...   \n",
       "96                      year 1        3.50 - 4.00             No   \n",
       "97                      Year 2        3.00 - 3.49             No   \n",
       "98                      Year 3        3.50 - 4.00            Yes   \n",
       "99                      year 4        3.50 - 4.00             No   \n",
       "100                     Year 2        3.00 - 3.49             No   \n",
       "\n",
       "    Do you have Depression? Do you have Anxiety? Do you have Panic attack?  \\\n",
       "0                       Yes                   No                       Yes   \n",
       "1                        No                  Yes                        No   \n",
       "2                       Yes                  Yes                       Yes   \n",
       "3                       Yes                   No                        No   \n",
       "4                        No                   No                        No   \n",
       "..                      ...                  ...                       ...   \n",
       "96                       No                  Yes                        No   \n",
       "97                      Yes                  Yes                        No   \n",
       "98                      Yes                   No                       Yes   \n",
       "99                       No                   No                        No   \n",
       "100                      No                   No                        No   \n",
       "\n",
       "    Did you seek any specialist for a treatment?  \n",
       "0                                             No  \n",
       "1                                             No  \n",
       "2                                             No  \n",
       "3                                             No  \n",
       "4                                             No  \n",
       "..                                           ...  \n",
       "96                                            No  \n",
       "97                                            No  \n",
       "98                                            No  \n",
       "99                                            No  \n",
       "100                                           No  \n",
       "\n",
       "[101 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caminho do arquivo CSV localizado na máquina do autor (substitua pelo seu caminho)\n",
    "file = r'D:\\Jeanco\\Meus projetos\\students_mental_health\\Student Mental health.csv'\n",
    "\n",
    "# Leitura do arquivo CSV utilizando a biblioteca pandas\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Visualização do DataFrame para verificar se o arquivo CSV foi lido corretamente\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padronização de Nomenclatura de Colunas\n",
    "\n",
    "Antes de nos aprofundarmos nos tópicos específicos mencionados no início deste projeto, optaremos por adotar convenções de nomenclatura mais consistentes para as colunas do conjunto de dados. Essa prática visa melhorar a legibilidade do código e facilitar a manipulação dos dados, especialmente durante processos de programação. Também colocaremos os nomes em Português do Brasil para facilitar a leitura nesse contexto.\n",
    "\n",
    "## Convenções Adotadas:\n",
    "\n",
    "1. **Minúsculas e Sublinhados (Snake Case):**\n",
    "   - Exemplo: `submission_time`, `choose_your_gender`, `age`, `course`, etc.\n",
    "\n",
    "## Por que estamos fazendo isso?\n",
    "\n",
    "Ao adotar essa abordagem, tornamos os nomes das colunas mais amigáveis para programação, facilitando a referência e a manipulação dos dados. Além disso, essa padronização contribui para a consistência no código e na análise, melhorando a clareza e a compreensão do conjunto de dados.\n",
    "\n",
    "Vamos aplicar essas convenções como no exemplo a seguir:\n",
    "```python\n",
    "# Exemplo de renomeação de colunas\n",
    "df.rename(columns={\n",
    "    'Timestamp': 'momento_envio',\n",
    "    'Choose your gender': 'genero',\n",
    "    'Age': 'idade',\n",
    "    'What is your course?': 'curso',\n",
    "    # ... (continuar para as demais colunas)\n",
    "}, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>momento_envio</th>\n",
       "      <th>genero</th>\n",
       "      <th>idade</th>\n",
       "      <th>curso</th>\n",
       "      <th>ano_estudo_atual</th>\n",
       "      <th>cgpa</th>\n",
       "      <th>estado_civil</th>\n",
       "      <th>tem_depressao</th>\n",
       "      <th>tem_ansiedade</th>\n",
       "      <th>tem_ataque_panic</th>\n",
       "      <th>buscou_especialista_para_tratamento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/7/2020 12:02</td>\n",
       "      <td>Female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>year 1</td>\n",
       "      <td>3.00 - 3.49</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/7/2020 12:04</td>\n",
       "      <td>Male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Islamic education</td>\n",
       "      <td>year 2</td>\n",
       "      <td>3.00 - 3.49</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/7/2020 12:05</td>\n",
       "      <td>Male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>BIT</td>\n",
       "      <td>Year 1</td>\n",
       "      <td>3.00 - 3.49</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/7/2020 12:06</td>\n",
       "      <td>Female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Laws</td>\n",
       "      <td>year 3</td>\n",
       "      <td>3.00 - 3.49</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/7/2020 12:13</td>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Mathemathics</td>\n",
       "      <td>year 4</td>\n",
       "      <td>3.00 - 3.49</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    momento_envio  genero  idade              curso ano_estudo_atual  \\\n",
       "0  8/7/2020 12:02  Female   18.0        Engineering           year 1   \n",
       "1  8/7/2020 12:04    Male   21.0  Islamic education           year 2   \n",
       "2  8/7/2020 12:05    Male   19.0                BIT           Year 1   \n",
       "3  8/7/2020 12:06  Female   22.0               Laws           year 3   \n",
       "4  8/7/2020 12:13    Male   23.0       Mathemathics           year 4   \n",
       "\n",
       "          cgpa estado_civil tem_depressao tem_ansiedade tem_ataque_panic  \\\n",
       "0  3.00 - 3.49           No           Yes            No              Yes   \n",
       "1  3.00 - 3.49           No            No           Yes               No   \n",
       "2  3.00 - 3.49           No           Yes           Yes              Yes   \n",
       "3  3.00 - 3.49          Yes           Yes            No               No   \n",
       "4  3.00 - 3.49           No            No            No               No   \n",
       "\n",
       "  buscou_especialista_para_tratamento  \n",
       "0                                  No  \n",
       "1                                  No  \n",
       "2                                  No  \n",
       "3                                  No  \n",
       "4                                  No  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Renomeando as colunas\n",
    "df.rename(columns={\n",
    "    'Timestamp': 'momento_envio',\n",
    "    'Choose your gender': 'genero',\n",
    "    'Age': 'idade',\n",
    "    'What is your course?': 'curso',\n",
    "    'Your current year of Study': 'ano_estudo_atual',\n",
    "    'What is your CGPA?': 'cgpa',\n",
    "    'Marital status': 'estado_civil',\n",
    "    'Do you have Depression?': 'tem_depressao',\n",
    "    'Do you have Anxiety?': 'tem_ansiedade',\n",
    "    'Do you have Panic attack?': 'tem_ataque_panic',\n",
    "    'Did you seek any specialist for a treatment?': 'buscou_especialista_para_tratamento'\n",
    "}, inplace=True)\n",
    "\n",
    "#Verificando as primeiras linhas da tabela\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"1\">1 - Lidar com dados ausentes</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivação:**\n",
    "   - Essa análise visa compreender a presença de dados ausentes no conjunto de dados, crucial para análises precisas.\n",
    "   - Em um conjunto de dados mais complexo, identificar e tratar dados ausentes é essencial para análises confiáveis.\n",
    "\n",
    "**Implicações:**\n",
    "   - Dados ausentes podem impactar a qualidade e validade das análises.\n",
    "   - A compreensão da distribuição de dados ausentes é fundamental para escolher estratégias adequadas de tratamento.\n",
    "\n",
    "Essa análise é fundamental para garantir que possamos abordar dados ausentes de maneira informada e eficaz em nosso conjunto de dados.\n",
    "\n",
    "A seguir analisaremos os dados em busca de \"ausências\" e proseguiremos com o tratamento e explicação prática da importância de lidarmos com esses vieses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "momento_envio\n",
      "False    101\n",
      "Name: count, dtype: int64\n",
      "\n",
      "genero\n",
      "False    101\n",
      "Name: count, dtype: int64\n",
      "\n",
      "idade\n",
      "False    100\n",
      "True       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "curso\n",
      "False    101\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ano_estudo_atual\n",
      "False    101\n",
      "Name: count, dtype: int64\n",
      "\n",
      "cgpa\n",
      "False    101\n",
      "Name: count, dtype: int64\n",
      "\n",
      "estado_civil\n",
      "False    101\n",
      "Name: count, dtype: int64\n",
      "\n",
      "tem_depressao\n",
      "False    101\n",
      "Name: count, dtype: int64\n",
      "\n",
      "tem_ansiedade\n",
      "False    101\n",
      "Name: count, dtype: int64\n",
      "\n",
      "tem_ataque_panic\n",
      "False    101\n",
      "Name: count, dtype: int64\n",
      "\n",
      "buscou_especialista_para_tratamento\n",
      "False    101\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_ausentes = df.isnull()\n",
    "for coluna in dados_ausentes.columns.values.tolist():\n",
    "    print(dados_ausentes[coluna].value_counts())\n",
    "    print(\"\")\n",
    "df.columns.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos abordar a questão dos dados ausentes, considerando que nosso conjunto de dados é simples, para fins didáticos. \n",
    "\n",
    "Abaixo está a explicação passo a passo do código utilizado acima para lidar com dados ausentes:\n",
    "\n",
    "1. **`dados_ausentes = df.isnull()`:**\n",
    "   - Criamos um DataFrame booleano indicando True para valores ausentes e False para valores presentes em `df`.\n",
    "2. **`for coluna in dados_ausentes.columns.values.tolist():`:**\n",
    "   - Iteramos por cada coluna no DataFrame de dados ausentes.\n",
    "3. **`print(dados_ausentes[coluna].value_counts())`:**\n",
    "   - Contamos e exibimos a quantidade de valores ausentes (True) e presentes (False) em cada coluna.\n",
    "4. **`print(df.columns.isnull())`:**\n",
    "   - Verificamos se há dados ausentes nos rótulos das colunas do DataFrame original, em outras palavras nos indica se algum nome de coluna está vazio. Isso pode ser útil em situações onde há a necessidade de verificar a integridade dos rótulos das colunas no DataFrame.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos às explicações para as saídas fornecidas por nosso código. Vejamos um exemplo:\n",
    "\n",
    "```\n",
    "momento_envio\n",
    "False    101\n",
    "Name: count, dtype: int64\n",
    "```\n",
    "\n",
    "Perceba que temos o nome da coluna ```momento_envio```. O False representa a quantidade de dados não nulos. Perceba que temos 101 valores não nulos para a coluna em questão. \n",
    "\n",
    "Agora veja a saída obtida para a coluna ```idade```:\n",
    "```\n",
    "idade\n",
    "False    100\n",
    "True       1\n",
    "Name: count, dtype: int64\n",
    "```\n",
    "\n",
    "\n",
    "- **`False: 100`:** Indica que há 100 valores não nulos na coluna \"idade\".\n",
    "- **`True: 1`:** Indica que há um valor nulo (ausente) na coluna \"idade\".\n",
    "\n",
    "As demais informações presentes nas saídas não são relevantes para o entendimento no escopo deste projeto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas qual é o valor que está no local do valor nulo na coluna \"idade\"? Vamos usar o método unique() para obter os valores exclusivos na coluna e descobrir isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18. 21. 19. 22. 23. 20. 24. nan]\n"
     ]
    }
   ],
   "source": [
    "print(df['idade'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A saída acima indica que na coluna idade temos 18 anos, 21 anos e assim por diante. Veja o último valor: nan.\n",
    "\n",
    "Agora identificamos que nosso valor nulo é representado por \"nan\" (not a number), permitindo-nos prosseguir com confiança na manipulação desse dado ausente. O uso consistente de \"nan\" como representação padrão traz benefícios em termos de consistência e compatibilidade em operações numéricas. Não é necessário compreender profundamente esses detalhes; o ponto chave é que o uso de \"nan\" como valor ausente é preferível a outras representações\n",
    "\n",
    "Entender que estamos lidando com \"nan\" nos permite empregar estratégias específicas, como substituição pela média ou pelo valor mais frequente, de maneira eficaz.\n",
    "\n",
    "**Importância de Saber o Valor no Nulo:**\n",
    "\n",
    "Conhecer o valor específico que ocupa o lugar do nulo é fundamental para a tomada de decisões informadas sobre como lidar com ele. Por exemplo, se o valor nulo fosse representado por um caractere específico, como \"?\", seria necessário identificar e tratar esse caractere de maneira única, evitando ambiguidades em operações numéricas e garantindo a coerência nos dados.\n",
    "\n",
    "Em resumo, a escolha da representação de valor nulo afeta diretamente a maneira como lidamos com esses valores durante a análise de dados, e optar por \"nan\" proporciona uma abordagem padronizada e eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 href=\"1.1\">1.1 - Substituição de valores nulos pela Média</h2>\n",
    "\n",
    "Quando lidamos com atributos que possuem dados contínuos, a abordagem mais adequada para substituir valores ausentes é utilizando a média. No nosso conjunto de dados, a variável \"idade\" é contínua, representando valores como 18, 21, 19, e assim por diante. Se alguns desses valores estiverem ausentes, podemos preenchê-los com a média da variável.\n",
    "\n",
    "Dados contínuos referem-se a variáveis que podem assumir qualquer valor dentro de um intervalo específico, como a idade, que pode ser representada por números reais. Em contraste com dados discretos, que assumem valores específicos e geralmente são inteiros, dados contínuos podem incluir frações ou números decimais.\n",
    "\n",
    "Utilizando o código abaixo, substituímos os valores ausentes na coluna \"idade\" pela média dessa mesma coluna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.   21.   19.   22.   23.   20.   24.   20.53]\n"
     ]
    }
   ],
   "source": [
    "media_idade = df['idade'].astype('float').mean(axis=0)\n",
    "df['idade'].replace(np.nan, media_idade, inplace=True)\n",
    "print(df['idade'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceba que agora temos o valor 20.53 em vez de 'nan'. Esse valor é a média de todas as idades apresentadas na coluna.\n",
    "\n",
    "A estratégia de substituição pela média é adotada para manter a coerência na distribuição dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 href=\"1.2\">1.2 - Substituição de valores nulos pelo valor mais Frequente</h2>\n",
    "\n",
    "### Exemplificativo\n",
    "\n",
    "Quando lidamos com atributos que contêm dados categóricos, a abordagem recomendada para substituir valores ausentes é utilizar o valor mais frequente na categoria. Vamos considerar o cenário em que temos uma coluna categórica, por exemplo, a coluna \"estado_civil\", e alguns valores estão ausentes. A estratégia apropriada seria substituir esses valores pelo estado civil mais frequente.\n",
    "\n",
    "Dados categóricos referem-se a variáveis que representam categorias discretas, como \"Solteiro\", \"Casado\" ou \"Divorciado\". Ao depararmos com valores ausentes nesse tipo de atributo, é benéfico preenchê-los com o valor mais comum da categoria, mantendo a integridade da distribuição.\n",
    "\n",
    "A seguir, apresento um código genérico que exemplifica como substituir, com o valor mais frequente, os valores ausentes na coluna categórica:\n",
    "\n",
    "```python\n",
    "valor_mais_frequente_estado_civil = df['estado_civil'].value_counts().idxmax()\n",
    "df['estado_civil'].replace(np.nan, valor_mais_frequente_estado_civil, inplace=True)\n",
    "```\n",
    "\n",
    "Essa abordagem garante que os valores ausentes sejam preenchidos de maneira representativa, isso visa manter a coesão na distribuição dos dados categóricos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 href=\"2\">2 - Correção de tipos de dados</h2>\n",
    "\n",
    "Antes de iniciar, gostaríamos de enfatizar que nossos dados possuem alguns desafios adicionais no momento da conversão e isso é justamente a fim de que possamos visualizar algumas possibilidades e opções de como os dados podem estar em sua forma bruta, ou seja, como eles vêm da fonte. Lembre-se que isso aqui não é um trabalho extensivo que esgota as possibilidades, mas uma visão geral com aplicações de conceitos chave que podem nos ajudar a desenvolver autonomia.\n",
    "\n",
    "**Motivação:**\n",
    "- A conversão é uma das etapas a serem seguidas no processo de preparação de dados, garantindo que as variáveis estejam no formato correto para análises subsequentes.\n",
    "- A escolha de tipos de dados apropriados otimiza o desempenho computacional, facilita operações matemáticas e contribui para uma interpretação mais clara das variáveis.\n",
    "\n",
    "**Implicações:**\n",
    "- A falta de conversão pode resultar em inconsistências nos resultados, prejudicando a confiabilidade das análises.\n",
    "- A padronização dos tipos de dados facilita a interpretação e execução de operações específicas, melhorando a eficácia das análises..\n",
    "\n",
    "A seguir, exploraremos a conversão de tipos em nosso conjunto de dados, exemplificando com casos práticos e destacando a importância dessa etapa no processo de manipulação e análise.\n",
    "\n",
    "Vamos analisar cada coluna e determinar a melhor abordagem para corrigir cada tipo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "momento_envio                           object\n",
       "genero                                  object\n",
       "idade                                  float64\n",
       "curso                                   object\n",
       "ano_estudo_atual                        object\n",
       "cgpa                                    object\n",
       "estado_civil                            object\n",
       "tem_depressao                           object\n",
       "tem_ansiedade                           object\n",
       "tem_ataque_panic                        object\n",
       "buscou_especialista_para_tratamento     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que vemos acima são os tipos de dados em cada coluna. À direita, temos o nome das colunas, e à esquerda, o tipo de dado presente. Nossa observação revela predominantemente dois tipos: object e float64. No contexto de Python, os dados podem ser representados de maneiras diversas, abrangendo números e textos. O tipo object é geralmente associado a dados textuais e, por outro lado, float64 representa dados numéricos.\n",
    "\n",
    "O que devemos considerar para corrigir os dados é a forma como eles serão utilizados no problema a ser resolvido, e para esse trabalho faremos algumas considerações gerais sobre como lidar com isso.\n",
    "\n",
    "Vejamos algumas colunas e possibilidades:\n",
    "\n",
    "```momento_envio```: Essa coluna deve ser convertida para o tipo de dado de data e hora (datetime), já que representa o momento de envio (data).\n",
    "\n",
    "Colunas com valores Yes e No (```tem_depressao```, ```tem_ansiedade```, ```tem_ataque_panic```, ```buscou_especialista_para_tratamento```):\n",
    "Se essas colunas representarem variáveis binárias, ou seja, valores 0 e 1 ou verdadeiro e falso; é uma prática comum convertê-las para o tipo de dado booleano (True ou False). Isso pode facilitar operações lógicas e análises futuras. Para nosso trabalho, vamos manter essas colunas como estão.\n",
    "\n",
    "```ano_estudo_atual```: Parece ser uma variável categórica representando o ano de estudo. Podemos convertê-la para o tipo de dado categórico.\n",
    "\n",
    "```cgpa```:  o termo \"CGPA\" geralmente se refere à \"Cumulative Grade Point Average\" em inglês, ou em português, \"Média Cumulativa de Notas\". O CGPA é uma métrica comumente usada em sistemas educacionais, especialmente em instituições que seguem o sistema de avaliação por notas.\n",
    "Esse valor é uma média ponderada das notas obtidas pelos alunos durante seu período de estudo. Ele reflete o desempenho acadêmico geral do aluno ao longo de um determinado período. Normalmente, as notas são convertidas para uma escala específica, e a média é calculada levando em consideração os créditos ou pesos associados a cada curso.\n",
    "\n",
    "Ao realizar análises no mundo real, lembre-se de explorar profundamente o conjunto de dados e suas características intrínsecas. Por questões didáticas, nos concentraremos nas explicações mais amplas neste contexto educativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "momento_envio                           object\n",
       "genero                                  object\n",
       "idade                                  float64\n",
       "curso                                   object\n",
       "ano_estudo_atual                        object\n",
       "cgpa                                    object\n",
       "estado_civil                            object\n",
       "tem_depressao                           object\n",
       "tem_ansiedade                           object\n",
       "tem_ataque_panic                        object\n",
       "buscou_especialista_para_tratamento     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Convertendo a coluna \"momento_envio\"\n",
    "\n",
    "Primeiro falaremos sobre casos mais complicados como o que será abordado a seguir, mas em geral o método ```astype()``` - sobre o qual falaremos mais adiante - é uma maneira comum de converter o tipo de dados de uma coluna. Para um trabalho básico como o nosso, essa explicação é suficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na coluna `momento_envio`, os dados incluem informações de data e hora. Seja qual for a abordagem adotada, ela precisará lidar com diferentes formatos de data, como dia/mês/ano, mês/ano/dia, com ou sem informações de horas.\n",
    "\n",
    "Para esse projeto não corrigiremos os dados dessa coluna, extensivamente, pois isso fugiria ao escopo simplificado que buscamos apresentar aqui; no entanto, faremos algumas considerações relevantes e interessantes e apresentaremos, a título exemplificativo, uma conversão. Leia com atenção:\n",
    "\n",
    "Ao lidar com dados que envolvem datas e horas, adentramos em um território que pode ser cheio de desafios e complexidades. A manipulação desses dados não é tão trivial quanto parece à primeira vista. Aqui estão algumas razões pelas quais dados referentes a datas e horas podem apresentar dificuldades consideráveis em sua manipulação/transformação.\n",
    "\n",
    "**Formatos Variados**: Datas podem ser apresentadas em diversos formatos, como \"dia/mês/ano\" ou \"ano/mês/dia\", e horários podem incluir ou não segundos. A variedade de representações adiciona complexidade ao processo de conversão.\n",
    "\n",
    "**Dados Ausentes ou Inconsistentes**: Muitas vezes, conjuntos de dados podem conter datas ausentes ou formatadas de maneira inconsistente. Isso pode resultar em erros durante a conversão para um formato padrão.\n",
    "\n",
    "**Fusos Horários**: Em ambientes globais, a presença de diferentes fusos horários pode complicar ainda mais a interpretação correta das datas e horas, especialmente se essas informações não estiverem claramente definidas.\n",
    "\n",
    "**Presença de Texto Adicional**: Às vezes, datas e horas podem estar \"misturadas\" a outros dados de texto, tornando necessário separar e converter essas informações de maneira cuidadosa.\n",
    "\n",
    "**Precisão e Granularidade**: Dependendo do contexto, pode ser necessário trabalhar com diferentes níveis de precisão temporal, como dias, horas, minutos ou até mesmo segundos. A manipulação precisa desses níveis de granularidade adiciona camadas de complexidade.\n",
    "\n",
    "É fundamental reconhecer que o processo de transformação de dados como os presentes na coluna ```momento_envio``` pode ser significativamente desafiador e apresentar diferentes níveis de complexidade. Em situações do mundo real, uma análise abrangente de datas e horas muitas vezes envolve considerações detalhadas e métodos avançados.\n",
    "\n",
    "Em nosso trabalho atual, estamos focando em conceitos mais básicos para proporcionar uma compreensão sólida, mas é importante estar ciente de que a manipulação de datas e horas pode se tornar uma jornada extensa e especializada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos os valores únicos presentes em nossa coluna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['8/7/2020 12:02', '8/7/2020 12:04', '8/7/2020 12:05',\n",
       "       '8/7/2020 12:06', '8/7/2020 12:13', '8/7/2020 12:31',\n",
       "       '8/7/2020 12:32', '8/7/2020 12:33', '8/7/2020 12:35',\n",
       "       '8/7/2020 12:39', '8/7/2020 12:40', '8/7/2020 12:41',\n",
       "       '8/7/2020 12:43', '8/7/2020 12:46', '8/7/2020 12:52',\n",
       "       '8/7/2020 13:05', '8/7/2020 13:07', '8/7/2020 13:12',\n",
       "       '8/7/2020 13:13', '8/7/2020 13:15', '8/7/2020 13:17',\n",
       "       '8/7/2020 13:29', '8/7/2020 13:35', '8/7/2020 13:41',\n",
       "       '8/7/2020 13:58', '8/7/2020 14:05', '8/7/2020 14:27',\n",
       "       '8/7/2020 14:29', '8/7/2020 14:31', '8/7/2020 14:41',\n",
       "       '8/7/2020 14:43', '8/7/2020 14:45', '8/7/2020 14:47',\n",
       "       '8/7/2020 14:56', '8/7/2020 14:57', '8/7/2020 14:58',\n",
       "       '8/7/2020 15:07', '8/7/2020 15:08', '8/7/2020 15:09',\n",
       "       '8/7/2020 15:12', '8/7/2020 15:14', '8/7/2020 15:18',\n",
       "       '8/7/2020 15:27', '8/7/2020 15:37', '8/7/2020 15:47',\n",
       "       '8/7/2020 15:48', '8/7/2020 15:57', '8/7/2020 15:58',\n",
       "       '8/7/2020 16:08', '8/7/2020 16:21', '8/7/2020 16:22',\n",
       "       '8/7/2020 16:34', '8/7/2020 16:53', '8/7/2020 17:05',\n",
       "       '8/7/2020 17:37', '8/7/2020 17:46', '8/7/2020 17:50',\n",
       "       '8/7/2020 18:10', '8/7/2020 18:11', '8/7/2020 19:05',\n",
       "       '8/7/2020 19:32', '8/7/2020 20:36', '8/7/2020 21:21',\n",
       "       '8/7/2020 22:35', '9/7/2020 6:57', '9/7/2020 11:43',\n",
       "       '9/7/2020 11:57', '9/7/2020 13:15', '9/7/2020 18:24',\n",
       "       '13/07/2020 10:07:32', '13/07/2020 10:10:30',\n",
       "       '13/07/2020 10:11:26', '13/07/2020 10:12:18',\n",
       "       '13/07/2020 10:12:26', '13/07/2020 10:12:28',\n",
       "       '13/07/2020 10:14:46', '13/07/2020 10:33:47',\n",
       "       '13/07/2020 10:34:08', '13/07/2020 11:46:13',\n",
       "       '13/07/2020 11:49:02', '13/07/2020 11:54:58',\n",
       "       '13/07/2020 13:57:11', '13/07/2020 14:38:12',\n",
       "       '13/07/2020 14:48:05', '13/07/2020 16:15:13',\n",
       "       '13/07/2020 17:30:44', '13/07/2020 19:08:32',\n",
       "       '13/07/2020 19:56:49', '13/07/2020 21:21:42',\n",
       "       '13/07/2020 21:22:56', '13/07/2020 21:23:57',\n",
       "       '18/07/2020 20:16:21'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['momento_envio'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao analisar os valores únicos na coluna \"momento_envio\", observamos alguns padrões e possíveis desafios que merecem atenção:\n",
    "\n",
    "Formato D/M/A e H:M: A maioria dos valores segue o padrão \"dia/mês/ano hora:minuto\", como exemplificado por '8/7/2020 12:02'. Isso é uma boa notícia, pois indica uma uniformidade considerável.\n",
    "\n",
    "Presença de Segundos: Alguns valores, como '13/07/2020 10:07:32', incluem informações de segundos. Essa variação no formato pode exigir atenção adicional ao realizar operações de conversão.\n",
    "\n",
    "Datas com Zeros à Esquerda: Algumas datas apresentam zeros à esquerda no dia e no mês, como '08/07/2020 18:11'. Embora isso não afete a conversão, pode ser relevante considerar a consistência nos dados.\n",
    "\n",
    "### Outros problemas que poderiam ser encontrados\n",
    "\n",
    "Variação na Separação: Poderíamos ter um conjunto de datas em que alguns valores usam barras (\"/\") como separadores, enquanto outros usam hifens (\"-\"). Isso pode ser uma fonte potencial de complexidade ao padronizar os dados.\n",
    "\n",
    "Ao lidar com esses desafios, devemos definir uma abordagem que leve em consideração a variedade de formatos sem comprometer a qualidade da conversão, assim será possível ajustar a estratégia para garantir uma manipulação eficaz e correta dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outras considerações sobre dados de data e hora\n",
    "\n",
    "O que acontece se a lista for extremamente extensa? Torna-se impraticável e improdutível para o analista verificar valor por valor, então quando se trata de entender a estrutura de dados em uma lista extensa, especialmente quando lidam pela primeira vez com essa lista, os analistas frequentemente adotam várias abordagens. Vamos descrever algumas possibilidades sem adentrarmos detalhadamente em cada uma\n",
    "\n",
    "**Visualização dos Primeiros Valores**: Os analistas geralmente começam visualizando os primeiros valores na lista para identificar padrões e formatos iniciais. Isso pode fornecer insights iniciais sobre a estrutura dos dados.\n",
    "\n",
    "**Uso de Métodos Descritivos**: A aplicação de métodos descritivos, como contar a frequência dos diferentes formatos, pode ajudar a identificar padrões predominantes e formatos menos comuns. Ferramentas como a função value_counts() no pandas podem ser úteis.\n",
    "\n",
    "**Amostragem Aleatória**: Em conjuntos de dados extensos, os analistas podem optar por amostrar aleatoriamente uma porção dos dados para uma análise mais detalhada. Isso ajuda a ter uma visão geral sem examinar cada valor individualmente.\n",
    "\n",
    "**Análise de Diferenças e Variações**: Ao examinar a lista, os analistas podem procurar variaçõaes nos formatos, como a presença ou ausência de segundos, diferentes separadores, etc. Isso ajuda a identificar possíveis desafios na padronização.\n",
    "\n",
    "**Utilização de Ferramentas Computacionais**: Ferramentas e métodos computacionais, como expressões regulares, podem ser empregados para identificar padrões específicos nos dados. Essas ferramentas são eficazes para lidar com listas extensas.\n",
    "\n",
    "No caso específico da coluna \"momento_envio\", considerando que estamos trabalhando em um ambiente de programação (Python), as funções do pandas, expressões regulares e métodos de manipulação de strings podem ser aplicados para explorar e entender os diferentes formatos presentes na lista.\n",
    "\n",
    "Não fique preocupado com tudo isso, é um trabalho que deve ser feito no dia a dia e que poderá ser desenvolvido, principalmente, com prática. Então tenha essas informações apenas como um gatilho mental, para quando começar a se aprofundar no conteúdo e realmente transformar colunas como essa, já possuir algum conhecimento prévio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais adiante apresentamos uma das abordagens possíveis (simples para o caso), que não considera todos os vieses que poderiam ser encotrados no momento da conversão (alguns dos vieses foram anteriormente destacados ).\n",
    "\n",
    "No código a seguir, ao utilizarmos o parâmetro format='%d/%m/%Y %H:%M:%S', especificamos o formato esperado para os dados na coluna 'momento_envio'. Isso serve para lidar com diferentes formatos e garantir a correta interpretação dos valores de data e hora. A presença de valores NaT (Not a Time) indica que houve valores não convertíveis ou ausentes, e o parâmetro errors='coerce' é útil para lidar com essas situações sem gerar erros, ou seja, se algum valor não pudesse ser convertido, seria então transformado em 'NaT'.\n",
    "\n",
    "Embora essa seja uma abordagem eficaz para o exemplo, na prática, a variedade de formatos de data e hora pode exigir uma análise mais aprofundada e talvez até o uso de expressões regulares ou métodos mais avançados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "[                'NaT', '2020-07-13 10:07:32', '2020-07-13 10:10:30',\n",
       " '2020-07-13 10:11:26', '2020-07-13 10:12:18', '2020-07-13 10:12:26',\n",
       " '2020-07-13 10:12:28', '2020-07-13 10:14:46', '2020-07-13 10:33:47',\n",
       " '2020-07-13 10:34:08', '2020-07-13 11:46:13', '2020-07-13 11:49:02',\n",
       " '2020-07-13 11:54:58', '2020-07-13 13:57:11', '2020-07-13 14:38:12',\n",
       " '2020-07-13 14:48:05', '2020-07-13 16:15:13', '2020-07-13 17:30:44',\n",
       " '2020-07-13 19:08:32', '2020-07-13 19:56:49', '2020-07-13 21:21:42',\n",
       " '2020-07-13 21:22:56', '2020-07-13 21:23:57', '2020-07-18 20:16:21']\n",
       "Length: 24, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converter a coluna 'momento_envio' para o formato datetime, considerando diferentes formatos\n",
    "df['momento_envio'] = pd.to_datetime(df['momento_envio'], errors='coerce', format='%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "# Exibir as primeiras linhas do DataFrame após a conversão\n",
    "df['momento_envio'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Convertendo a coluna ano_estudo_atual\n",
    "\n",
    "Agora adentramos em conversões utilizando o método astype(). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year 1', 'year 2', 'Year 1', 'year 3', 'year 4', 'Year 2', 'Year 3']\n",
       "Categories (7, object): ['Year 1', 'Year 2', 'Year 3', 'year 1', 'year 2', 'year 3', 'year 4']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ano_estudo_atual'] = df['ano_estudo_atual'].astype('category')\n",
    "df['ano_estudo_atual'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao converter a coluna 'ano_estudo_atual' para o tipo categórico, e ao utilizarmos o método ```unique()```, obtivemos uma visão dos valores únicos ali presentes. Percebe-se que existem variações na forma como os anos de estudo são representados, incluindo diferentes capitalizações (maiúsculas e minúsculas).\n",
    "\n",
    "Para padronizar esses valores, podemos optar por converter todos os valores para minúsculas, por exemplo, e então reavaliar os valores únicos para garantir uma consistência na representação. Isso pode ser feito da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year 1', 'year 2', 'year 3', 'year 4']\n",
       "Categories (4, object): ['year 1', 'year 2', 'year 3', 'year 4']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converte todos os valores da coluna 'ano_estudo_atual' para letras minúsculas\n",
    "df['ano_estudo_atual'] = df['ano_estudo_atual'].str.lower()\n",
    "\n",
    "# Converte a coluna 'ano_estudo_atual' para o tipo 'category'\n",
    "df['ano_estudo_atual'] = df['ano_estudo_atual'].astype('category')\n",
    "\n",
    "# Exibe os valores únicos após a conversão\n",
    "df['ano_estudo_atual'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Com a conversão da coluna \"ano_estudo_atual\" para o tipo categórico e a posterior padronização dos valores para letras minúsculas, alcançamos uma consistência na representação dos anos de estudo. A conversão efetuada garante uniformidade nos dados, e por consequência facilita análises e interpretações futuras. Agora seguiremos com a conversão da coluna ```cgpa```, a qual nos trará outros desafios adicionais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Convertendo a coluna cgpa\n",
    "\n",
    "Antes de começarmos a discutir a conversão dos dados em ```cgpa```, vamos dar uma olhada nos valores únicos da coluna a fim de termos uma compreensão da forma como eles são apresentados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3.00 - 3.49', '3.50 - 4.00', '3.50 - 4.00 ', '2.50 - 2.99',\n",
       "       '2.00 - 2.49', '0 - 1.99'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cgpa'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Coluna CGPA: Lidando com valores intervalares\n",
    "\n",
    "Ao explorar a coluna CGPA, notamos que os dados estão apresentados de forma métrica, representando intervalos como '3.00 - 3.49', '3.50 - 4.00', etc. Esses intervalos sugerem faixas específicas de Médias Cumulativas de Notas (CGPA), proporcionando uma visão geral do desempenho acadêmico dos alunos.\n",
    "\n",
    "Agora, para tornar esses intervalos mais significativos numericamente, recorreremos ao uso de expressões regulares (regex). Vamos entender como isso funciona:\n",
    "\n",
    "#### Entendendo Expressões Regulares de Forma Simples:\n",
    "Expressões regulares, ou regex, são padrões de caracteres que facilitam a busca e manipulação de textos. No contexto da coluna CGPA, onde os valores estão no formato '3.00 - 3.49', a expressão regular simples ```\\d+\\.\\d+``` nos ajuda a extrair os números ali contidos.\n",
    "\n",
    "- \\d: representa qualquer dígito de 0 a 9.\n",
    "- +: indica que o caractere anterior (no nosso caso, \\d) pode aparecer uma ou mais vezes.\n",
    "- \\.: procura por um ponto decimal, precedido por uma barra invertida para ser interpretado literalmente.\n",
    "\n",
    "Dito isso nossa próxima etapa é converter esses \"intervalos textuais\" em valores numéricos mais representativos. Entendemos que cada intervalo abrange uma faixa de valores, e para simplificar a análise, assumiremos a média desse intervalo como seu valor representativo. Se não entendeu o que isso quer dizer ainda, buscaremos um valor entre os valores apresentados no intervalo e esse valor será a média entre eles.\n",
    "\n",
    "##### Escolhendo a Técnica Certa:\n",
    "Como já vimos, a coluna ```cgpa``` tem seus dados em formato textual (string) e precisamos extrair os números ali apresentados. Então, para extrair números de strings, a utilização de expressões regulares é uma escolha comum e poderosa.\n",
    "\n",
    "##### Como Utilizar:\n",
    "É útil entender o padrão dos dados que estamos tentando extrair. No nosso caso, o padrão foi apresentado enquanto explicávamos o que são expressões regulares. Existem recursos online e bibliotecas em Python, como a re, que fornecem ajuda na criação de expressões regulares. A intenção não é ensinar a resolver todos os casos possíveis, mas mostrar a forma como dados podem ser apresentados e como isso impacta na escolha do tipo de tratamento a ser dado em determinada situação.\n",
    "\n",
    "Abaixo criamos uma função chamada ```calcular_media```. Essa função utiliza a biblioteca re (expressões regulares) para extrair todos os números decimais (\\d+.\\d+) de uma string que representa um intervalo, como '3.00 - 3.49'. A função então converte esses números para o formato float e calcula a média entre eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a biblioteca re, que lida com expressões regulares\n",
    "import re\n",
    "\n",
    "# Definindo uma função chamada calcular_media\n",
    "def calcular_media(intervalo):\n",
    "    # Utilizando re.findall para encontrar todos os padrões de números decimais na string do intervalo\n",
    "    numeros_encontrados = re.findall(r'\\d+\\.\\d+', intervalo)\n",
    "    \n",
    "    # Inicializando uma lista vazia para armazenar os números convertidos\n",
    "    numeros_convertidos = []\n",
    "    \n",
    "    # Iterando sobre cada número encontrado na lista\n",
    "    for numero in numeros_encontrados:\n",
    "        # Convertendo cada número para o tipo de dado float e adicionando à lista numeros_convertidos\n",
    "        numeros_convertidos.append(float(numero))\n",
    "    \n",
    "    # Calculando a média dos números na lista numeros_convertidos\n",
    "    media = sum(numeros_convertidos) / len(numeros_convertidos)\n",
    "    \n",
    "    # Retornando a média calculada\n",
    "    return media\n",
    "\n",
    "# Aplicando a função calcular_media à coluna 'cgpa' do DataFrame df\n",
    "df['cgpa'] = df['cgpa'].apply(calcular_media)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101 entries, 0 to 100\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   cgpa    101 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 940.0 bytes\n"
     ]
    }
   ],
   "source": [
    "# Checando as informações sobre a coluna cgpa\n",
    "df[['cgpa']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A estratégia utilizada foi pensada de forma didática, visando facilitar a compreensão, especialmente para iniciantes. Após a aplicação dessa abordagem, podemos observar que a coluna \"cgpa\" agora exibe os valores convertidos e tratados de maneira adequada -  verifique acima o DTYPE na linha iniciada com uma hashtag.\n",
    "\n",
    "Tenha em consideração que as abordagens apresentadas refletem algumas nuances do mundo real que não poderiam ser resolvidas utilizando a conversão apenas com o método ```astype()```, de qulalquer forma, para encerrar esta seção, disponibilizamos o link para a documentação oficial do Pandas, onde você pode encontrar informações detalhadas sobre o método astype() e seu uso para conversões de tipos de dados:\n",
    "\n",
    "<a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.astype.html\">Método astype() - Documentação Pandas</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
